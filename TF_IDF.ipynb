{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "from numpy import argmax\n",
    "\n",
    "path_to_vectorizer = 'vectorizer'\n",
    "path_data_frame = 'parallelCorpus'\n",
    "path_to_document_tfidf = 'source-tfidf'\n",
    "threshold = .7\n",
    "\n",
    "def removeSingleDoubleCharacterWordStopWordsAndStemming(tokens):\n",
    "    ps = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [ps.stem(token) for token in tokens if token not in stop_words] \n",
    "#     print(tokens) \n",
    "    return ' '.join([token for token in tokens if len(token)>2 and token not in stop_words])\n",
    "\n",
    "def removePunctuationAndGetTokens(lines):\n",
    "    pattern = re.compile('[0-9].*')\n",
    "    lines = re.sub(pattern,' ',lines)\n",
    "    translator = str.maketrans(string.punctuation,' '*len(string.punctuation))\n",
    "    lines = lines.translate(translator)\n",
    "    tokens = lines.split()\n",
    "    return tokens\n",
    "\n",
    "def calculate_tfidf_of_documents(dataframe_file):\n",
    "    df = load_dataFrame(dataframe_file)\n",
    "    tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "    tfidf_documents=tfidf_vectorizer.fit_transform(df['English'].apply(removeSingleDoubleCharacterWordStopWordsAndStemming).values.astype('U'))\n",
    "    return tfidf_vectorizer,tfidf_documents\n",
    "\n",
    "def load_dataFrame(filePath):\n",
    "    return pd.read_json(filePath+'.json')\n",
    "\n",
    "def calculate_tfidf_of_query(query,tfidf_vectorizer):\n",
    "    processed_query = removeSingleDoubleCharacterWordStopWordsAndStemming(removePunctuationAndGetTokens(query))\n",
    "    return tfidf_vectorizer.transform([query])\n",
    "\n",
    "def main():\n",
    "    vectorizer, doc_tf_idf = calculate_tfidf_of_documents(path_data_frame)\n",
    "    save_vectors(vectorizer,path_to_vectorizer)\n",
    "    save_vectors(doc_tf_idf,path_to_document_tfidf)\n",
    "    \n",
    "def save_vectors(vector,filename):\n",
    "    pickle.dump(vector, open(filename+'.pk', 'wb'),protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def get_relevant_document_list(query):\n",
    "    docu_df = load_dataFrame(path_data_frame)\n",
    "    vectorizer = load_vectors(path_to_vectorizer)\n",
    "    query_tfidf = calculate_tfidf_of_query(query,vectorizer)\n",
    "    doc_tfidf = load_vectors(path_to_document_tfidf)\n",
    "    similarity = cosine_similarity(doc_tfidf,query_tfidf)\n",
    "    flat = similarity.flatten()\n",
    "    index = argmax(flat)\n",
    "    probability = flat[index])\n",
    "    return ' '.join(docu_df.iloc[index,1]),probability\n",
    "\n",
    "def load_vectors(filename):\n",
    "    with open(filename+'.pk', 'rb') as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "def talk_like_shakespeare():\n",
    "    input_sentence = input('English: ')\n",
    "    output_sentence, probability = get_relevant_document_list(input_sentence)\n",
    "    if(probability > threshold):\n",
    "        print('Shakespeare: {}'.format(output_sentence))\n",
    "    else:\n",
    "        # call your model here and display output\n",
    "    \n",
    "    \n",
    "# query = input()\n",
    "get_relevant_document_list(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1096 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataFrame(filePath):\n",
    "    return pd.read_json(filePath+'.json')\n",
    "\n",
    "df = load_dataFrame('parallelCorpus')\n",
    "\n",
    "df.iloc[999,:]\n",
    "vectorizer = load_vectors(path_to_vectorizer)\n",
    "calculate_tfidf_of_query('a jumbled confession can only receive a jumbled absolution',vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
